{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3daa8db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.signal import butter, lfilter, medfilt, cheby1, sosfilt # decimate\n",
    "# from scipy.stats import median_abs_deviation\n",
    "import pandas as pdf\n",
    "# import math\n",
    "import librosa\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_path = \"/home/collins/Desktop/projects/baymax/data/Respiratory_Sound_Database/\"\n",
    "audio_file_path = f\"{data_path}audio_and_txt_files\"\n",
    "\n",
    "# patient_number = \"122\" # Those with pneumonia in the dataset are 122, 135, 140, 191, 219 and 226\n",
    "# sound_location = \"\"\n",
    "\n",
    "# Colors\n",
    "plot_colors = {\n",
    "    \"Tc\": \"#32F2F5\",\n",
    "    \"Al\": \"#FA9A0A\",\n",
    "    \"Ll\": \"#F53532\",\n",
    "    \"Pl\": \"#2AC126\",\n",
    "    \"Ar\": \"#0A6AFA\",\n",
    "    \"Pr\": \"#BD26C1\",\n",
    "    \"Lr\": \"#32F2F5\"\n",
    "}\n",
    "\n",
    "def remove_spikes(data):\n",
    "    # Calculate the median absolute deviation (MAD) of the signal\n",
    "    # mad = math.floor(median_abs_deviation(data))\n",
    "\n",
    "    # Determine the window size based on the MAD\n",
    "    # ws = mad * 10\n",
    "    \n",
    "    # Ensure window size is odd\n",
    "    ws = 501 # ws if ws % 2 else ws + 1\n",
    "    \n",
    "    # print(ws)\n",
    "    \n",
    "    filtered_signal = medfilt(data)\n",
    "    \n",
    "#     b, a = butter(3, [50/(0.5*sampling_rate), 2500/(0.5*sampling_rate)], 'band')    \n",
    "#     data = lfilter(b, a, data)\n",
    "\n",
    "    return filtered_signal\n",
    "\n",
    "# High pass filter function to remove heart sounds\n",
    "def filterNoise(sampling_rate, data):\n",
    "    # Butterworth band pass filter with cutoff frequencies\n",
    "    # as a fraction of nquist frequency (1/2 the sampling rate)\n",
    "    b, a = butter(3, [300/(0.5*sampling_rate), 1000/(0.5*sampling_rate)], 'band')\n",
    "\n",
    "    signal = lfilter(b, a, data)\n",
    "    \n",
    "    # Resample the resulting signal to 4000 Hz\n",
    "    # signal = decimate(signal, int(sampling_rate/4000))\n",
    "\n",
    "    return signal\n",
    "\n",
    "\n",
    "def fourierTransform():\n",
    "    # Fourier transform for Frequency domain\n",
    "    # plt.subplot(1,2,2)\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.title(f\"Frequency domain of {diagnosis} patient {patient_number}\")\n",
    "    \n",
    "    for z in files:\n",
    "        file_name = files[z]\n",
    "        if file_name:\n",
    "            sr, data = wavfile.read(f\"{audio_file_path}/{file_name}\")\n",
    "            number_of_samples = data.shape[0]\n",
    "            yf = rfft(data)\n",
    "            # yf_normalized = np.abs(yf) / np.max(np.abs(yf))\n",
    "            xf = rfftfreq(number_of_samples, 1/sr)\n",
    "            plt.plot(xf, np.abs(yf), label=z)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"waveforms/{patient_number}_{diagnosis}_freqdom.png\")\n",
    "    plt.close()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def createSpectogram():\n",
    "    return\n",
    "\n",
    "\n",
    "def wavToArray(file):\n",
    "    # sr, data = wavfile.read(f\"{audio_file_path}/{file}\")\n",
    "    # Loading with librosa resamples the data to the specified\n",
    "    # frequencey (4000Hz) and normalizes the data between 1 and -1\n",
    "    data, sr = librosa.core.load(f\"{audio_file_path}/{file}\", sr=4000)\n",
    "    return sr, data\n",
    "\n",
    "\n",
    "def getMelSpectogram():\n",
    "    return\n",
    "\n",
    "\n",
    "def createlPlots(patient_number, files, diagnosis, chest_location=''):\n",
    "    # Time domain\n",
    "    fig, axs = plt.subplots(2,2, figsize=(15, 6))\n",
    "    \n",
    "\n",
    "    axs[0][0].set_xlabel(\"Time [s]\")\n",
    "    axs[0][1].set_xlabel(\"Time [s]\")\n",
    "    axs[1][0].set_xlabel(\"Time [s]\")\n",
    "    axs[0][0].set_ylabel(\"Amplitude\")\n",
    "    axs[0][1].set_ylabel(\"Amplitude\")\n",
    "    axs[1][0].set_ylabel(\"Frequency\")\n",
    "    axs[0][0].set_title(f\"a)\")\n",
    "    axs[0][1].set_title(f\"b)\")\n",
    "    axs[1][0].set_title(f\"c)\")\n",
    "\n",
    "    for y in files:\n",
    "        file_name = files[y]\n",
    "        if file_name:\n",
    "            sr, raw_signal = wavToArray(file_name)\n",
    "            signal = filterNoise(sr, raw_signal) # Remove cardiac sounds\n",
    "            time = np.linspace(0, raw_signal.shape[0]/sr, raw_signal.shape[0])\n",
    "            rtime = np.linspace(0, signal.shape[0]/4000, signal.shape[0])\n",
    "\n",
    "            axs[0][0].plot(time, raw_signal, label=y, color=plot_colors[y])\n",
    "            axs[0][1].plot(rtime, signal, label=y, color=plot_colors[y])\n",
    "\n",
    "            S = librosa.feature.melspectrogram(y=signal, sr=4000, n_mels=256, fmax=1500, n_fft=8000)\n",
    "            # n_fft is the window size -> We make it 2X the sr, because we assume a complete\n",
    "            # respiratory phase takes 2 seconds -> 1 second inhale, 1 second exhale\n",
    "            S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "            img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=4000, ax=axs[1][0])\n",
    "            fig.colorbar(img, ax=axs[1][0], format='%+2.0f dB')\n",
    "            axs[1][0].set(title='c)')\n",
    "\n",
    "    axs[0][0].legend()\n",
    "    axs[0][1].legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"waveforms/{patient_number}_{diagnosis}_timedom{chest_location}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f274bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data - List with dicts of format\n",
    "# {\"patient_number\": {\"Al\": {\"annotation\":{\"\"}}, \"Tc\": \"\", \"Ar\": \"\", \"\": \"\"}}\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "demographics_file = f\"{data_path}/demographic_info.csv\"\n",
    "events_path = f\"{data_path}events\"\n",
    "diagnosis_file = f\"{data_path}patient_diagnosis.csv\"\n",
    "\n",
    "\n",
    "df = pdf.read_csv(diagnosis_file, header=None, names=[\"patient_no\", \"diagnosis\"])\n",
    "df = df[df['diagnosis'].isin([\"Healthy\", \"Pneumonia\"])] # Only deal with pneumonia and healthy\n",
    "\n",
    "\n",
    "df2 = pdf.read_csv(demographics_file, header=None, names=[\"patient_no\", \"age\", \"sex\", \"adult_bmi\", \"child_weight\", \"child_height\"])\n",
    "df3 = pdf.merge(df, df2, on=\"patient_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce1de1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for each chest location\n",
    "df3[\"Tc\"] = None\n",
    "df3[\"Al\"] = None\n",
    "df3[\"Pl\"] = None\n",
    "df3[\"Ll\"] = None\n",
    "df3[\"Ar\"] = None\n",
    "df3[\"Pr\"] = None\n",
    "df3[\"Lr\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8da054ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in os.listdir(audio_file_path):\n",
    "    p = d.split(\"_\")\n",
    "\n",
    "    if p[4].split(\".\")[1] == \"wav\":\n",
    "        df3.loc[df3['patient_no'] == int(p[0]), p[2]] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2df693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _, row in df3.iterrows():\n",
    "#     plotSoundWaveform(\n",
    "#         row['patient_no'],\n",
    "#         {\n",
    "#          \"Tc\": row['Tc'], \"Al\": row['Al'],\n",
    "#          \"Pl\": row['Pl'], \"Ll\": row['Ll'],\n",
    "#          \"Ar\": row['Ar'], \"Pr\": row['Pr'],\n",
    "#          \"Lr\": row['Lr']\n",
    "#         },\n",
    "#         row['diagnosis']\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffdb7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for single chest locations\n",
    "# for _, row in df3.iterrows():\n",
    "#     for c_loc in ['Tc', 'Pl', 'Pr', 'Ll', 'Lr', 'Al', 'Ar']:\n",
    "#         if row[c_loc]:\n",
    "#             plotSoundWaveform(\n",
    "#                 row['patient_no'],\n",
    "#                 {\n",
    "#                     c_loc: row[c_loc]\n",
    "#                 },\n",
    "#                 row['diagnosis'],\n",
    "#                 c_loc\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ee02df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pneumonia patient and healthy patient samples\n",
    "# for _, pp in df3.loc[df3[\"patient_no\"].isin([135,159])].iterrows():\n",
    "#     plotSoundWaveform(\n",
    "#         pp['patient_no'],\n",
    "#         {\n",
    "#          \"Tc\": pp['Tc'], \"Al\": pp['Al'],\n",
    "#          \"Pl\": pp['Pl'], \"Ll\": pp['Ll'],\n",
    "#          \"Ar\": pp['Ar'], \"Pr\": pp['Pr'],\n",
    "#          \"Lr\": pp['Lr']\n",
    "#         },\n",
    "#         pp['diagnosis']\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a62d8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for single chest locations\n",
    "# from tensorflow import keras\n",
    "\n",
    "for _, pp in df3.loc[df3[\"patient_no\"].isin([135,159])].iterrows():\n",
    "    createlPlots(\n",
    "        pp['patient_no'],\n",
    "        {\n",
    "            \"Ar\": pp['Ar']\n",
    "        },\n",
    "        pp['diagnosis']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b0f6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class SoundDS(Dataset):\n",
    "  def __init__(self, df, data_path):\n",
    "    self.df = df\n",
    "    self.data_path = str(data_path)\n",
    "    self.duration = 4000\n",
    "    self.sr = 44100\n",
    "    self.channel = 2\n",
    "    self.shift_pct = 0.4\n",
    "            \n",
    "  # ----------------------------\n",
    "  # Number of items in dataset\n",
    "  # ----------------------------\n",
    "  def __len__(self):\n",
    "    return len(self.df)    \n",
    "    \n",
    "  # ----------------------------\n",
    "  # Get i'th item in dataset\n",
    "  # ----------------------------\n",
    "  def __getitem__(self, idx):\n",
    "    # Absolute file path of the audio file - concatenate the audio directory with\n",
    "    # the relative path\n",
    "    audio_file = self.data_path + self.df.loc[idx, 'file']\n",
    "    # Get the Class ID\n",
    "    class_id = self.df.loc[idx, 'diagnosis']\n",
    "\n",
    "    aud = AudioUtil.open(audio_file)\n",
    "    # Some sounds have a higher sample rate, or fewer channels compared to the\n",
    "    # majority. So make all sounds have the same number of channels and same \n",
    "    # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
    "    # result in arrays of different lengths, even though the sound duration is\n",
    "    # the same.\n",
    "    reaud = AudioUtil.resample(aud, self.sr)\n",
    "    rechan = AudioUtil.rechannel(reaud, self.channel)\n",
    "\n",
    "    dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
    "    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "    return aug_sgram, class_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
